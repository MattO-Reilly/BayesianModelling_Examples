---
title: "Assignment 3"
author: "Matt O'Reilly"
output:
word_document: default
html_document:
df_print: paged
pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
library(LearnBayes)
library(dplyr)
library(ggplot2)
source("TeachBayes.r") ## put the TeachBayes.r file in the same folder as this Rmd file
```

## Example 1
It rains a lot in Galway. How often do you think it rains? Let's set up a Bayesian analysis to combine your belief about rain in Galway with some data. We'll treat each day as independent and suggest that $X$, the number of days it rains in Galway, is Binomially distributed, i.e. $X \sim Bin(n,\theta)$

I specified my prior using the 0.50 and the 0.90 quantiles. From intuition I asssigned appropriate values to my p50 and p90 (where p50 represents the 0.50 quantile for $\theta$ meaning it is equally likely to be smaller or larger than p50 and p90 represents the 0.90 quantile for $\theta$ meaning it is likely with probability 0.90 to be smaller than p90). 

I selected 0.65 for my p50 because I believe it rains in galway slightly more often than 50% of the time. I then selected p90 to be 0.85 because I suspect the distribution of rainfall over a period of time to be left-skewed.

```{r}
p50 <- list(x = 0.65, p = 0.5)
p90 <- list(x = 0.85, p = 0.9)

## Find the matching beta curve
my_shapes <- beta.select(p50, p90)
my_shapes

beta_draw(my_shapes)
```

```{r}
prior_par <- c(my_shapes[1], my_shapes[2])
```

We collected data ourselves on rain in Galway over the course of a few days. The total number of days on which we collected data is $n$, and the total number of days with rain is $x$. The updated prior proportion is as follows. 

```{r}
data <- c(7,4)
post_par <- prior_par + data
post_par

beta_prior_post(prior_par, post_par)
```
From the updated posterior probability distribution we can see that the data has shifted slightly to the left. We can see from the shape of our posterior curve that our data is more accurate. The mode is now approximately at $\theta$ = 0.63

```{r}
#Point Interval Alpha/(Alpha + Beta)
point_estimate <- (11.54/(11.54+6.59))
point_estimate

beta_interval(0.95, c(my_shapes[1]+7, my_shapes[2]+4))

```
From our interval estimate we can say with 95% confidence that the probability of $\theta$ is between 0.41 and 0.835.

We looked up the weather reports and found the exact same data occurred last year. 

```{r}
prior_new <- prior_par + data
posterior_new <- prior_par + 2*data
beta_prior_post(prior_new, posterior_new) 

```

```{r}
beta_interval(0.95, posterior_new)
```
After updating our posterior with data that backs up my previous results as expected the shape of our updated posterior probability distribution is more accurate and slightly shifted to the right. The mode is still centered around a value of approximately $\theta$ = 0.6365. Looking at our updated interval estimate we can say with 95% confidence that the probability of $\theta$ is between 0.457 and 0.798.

Lets check to see if it rains less than 20% of the time in Galway.

```{r}
beta_area(0, 0.2,posterior_new)
```
This suggests that there is no chance that it rains less than 20% of the time in Galway. We reject the tourist agency’s claim.

lets Simulate 10000 observations from our updated posterior
```{r}
mysims <- rbeta(10000, shape1 = posterior_new[1],shape2 = posterior_new[2])
```

Using these simulated data, we can compute a 95% probability interval for $\theta$ and compare it to the one you found earlier.


```{r question1}
quantile(mysims, probs = 0.025)
quantile(mysims, probs = 0.975)
```

The 95% probability interval obtained from simulating 10,000 observations is very close to the interval we obtained earlier. We observe that the upper and lower quartiles generated from the simulated data are approximately equal to the upper and lower quartiles we found earlier. We expect as the number of simulations increases we will obtain an interval closer in value to that of the one we obtained earlier.

## Example 2

Let's try to estimate $X$ the number of emails you receive in a day. This will be a count variable since we can only get non-negative integer values.

X is a discrete outcome. Since X is a count, we can model its dependence on $\theta$ by the Poisson distribution. This would best display the data we observe.

We selected five emails as our mean amount of emails per day and two as our standard deviation as we belive these to be appropriate assumptions. We used the mean and standard deviation to calculate $\beta$ and $\alpha$.

```{r}
mean=5
sd=2
my_alpha=(mean^2)/(sd^2)
my_beta=mean/(sd^2)
x <- seq(0, 12 ,length=100)
priorx <- dgamma(x, shape=my_alpha, rate=my_beta)
plot(x, priorx, type='l',lwd=3,xlim = c(0,12),ylim = c(0,0.3),col = 'blue',
main = '', xlab = 'theta', ylab = '')

```

Lets suppose we receive the following number of emails over the next 10 days, Lets update our prior belief and form a posterior distribution for the underlying rate of emails received per day.

```{r}
n=10
observations=c(1,5,4,4,2,2,3,1,4,5)

post_alpha= my_alpha + sum(observations)
post_beta= my_beta + n
postx <- dgamma(x, shape= post_alpha, rate= post_beta)
plot(x, priorx, type='l',lwd=3,xlim = c(0,12),ylim = c(0,0.8), col = 'blue',
main = 'Prior', xlab = 'theta', ylab = '')
lines(x, postx,lwd=3,col='red')
legend("topright", c("Prior","Posterior"), lty = 1, lwd= 3, col = c('blue','red'))

```

From the updated posterior probability distribution we observe that the data has shifted to the left. It is evident from the shape of our posterior curve that our data is more accurate. The mode is now approximately at $\theta$ = 3.4

Lets calculate a point and an interval estimate for our posterior

```{r}
point_est= post_alpha/post_beta
point_est

qgamma(0.025, shape = post_alpha, rate = post_beta)

qgamma(0.975, shape = post_alpha, rate = post_beta)

plot(x, postx, type = 'l', ylim = c(0,1.2), lwd=3,col = 'red', main = 'Posterior', xlab = 'theta')
abline(v= qgamma(0.025, shape = post_alpha, rate = post_beta), lty = 'dashed', lwd = 2)
abline(v= qgamma(0.975, shape = post_alpha, rate = post_beta), lty = 'dashed', lwd = 2)

```
From the interval estimate we can conclude that the probability that $\theta$ is between 2.334322 and 4.455955 is 0.95.

Now, Over the next few days we receieve the following number of emails 10, 4, 3, 7 and 4. 
```{r}
tot_emails<-c(observations,10,4,3,7,4)

post2_alpha= my_alpha + sum(tot_emails)
post2_beta= my_beta + n
post2x <- dgamma(x, shape= post2_alpha, rate= post2_beta)
plot(x, postx, type='l',lwd=3,xlim = c(0,12),ylim = c(0,0.8), col = 'blue',
main = 'Prior', xlab = 'theta', ylab = '')
lines(x, post2x,lwd=3,col='red')
legend("topright", c("Prior","Posterior"), lty = 1, lwd= 3, col = c('blue','red'))

point2_est= post2_alpha/post2_beta
point2_est

qgamma(0.025, shape = post2_alpha, rate = post2_beta)

qgamma(0.975, shape = post2_alpha, rate = post2_beta)

plot(x, post2x, type = 'l', ylim = c(0,1.2), lwd=3,col = 'red', main = 'Posterior', xlab = 'theta')
abline(v= qgamma(0.025, shape = post2_alpha, rate = post2_beta), lty = 'dashed', lwd = 2)
abline(v= qgamma(0.975, shape = post2_alpha, rate = post2_beta), lty = 'dashed', lwd = 2)
```
From the new updated posterior probability distribution we observe that the data has shifted to the right. It is evident from the shape of our posterior curve that our data is more accurate. The mode is now approximately at $\theta$ = 5.8

From the interval estimate we can conclude that the probability that $\theta$ is between 4.478687 and 7.289509 is 0.95.

What is the likelihood that the total number of emails students receive is 3.2 per day?
```{r}
pgamma(3.2, shape = post_alpha, rate = post_beta)
```
There is a 0.4394591 probability that the total number of emails students receive is 3.2 per day on average. We fail to reject the student’s claim.

Simulate 10000 observations from your updated posterior. 
```{r}
mysims <- rgamma(10000, shape = post2_alpha, rate = post2_beta)
```

```{r}
quantile(mysims, probs = c(0.025, 0.975))
```
Simliar to Q1 the 95% probability interval obtained from simulating 10000 observations is very close to the value of the interval we obtained earlier. We observe that the upper and lower quartiles generated from the simulated data are approximately equal to the upper and lower quartiles we found earlier. We expect as the number of simulations increases we will obtain an interval closer in value to that of the one we obtained earlier.


## Example 3

A person's daily screen time $X$ depends on a number of factors, including the time of day, weather, news events and sports results. Let's say that daily phone screen time is Normally distributed with mean $\theta$ and known standard deviation $\sigma$, i.e. $X\sim N(\theta,\sigma^2)$. We will assume that $\sigma$ is 30 minutes.

Our prior distribution for $\theta$, the mean screen time of students is;
```{r}
mu0 <- 125
sigma0 <- 30
```

For this example screen time data is given to us. 
```{r}
n = 10
times <- c(115,122,119,102,98,119,134,145,110,98)
mean_t <- (sum(times))/n
mean_t
se = 5/sqrt(n)

post_mean = (1/(se^2) + 1/(sigma0^2))^(-1)*(mean_t/(se^2) + mu0/(sigma0^2))
post_sd = sqrt((1/(se^2) + 1/(5^2))^(-1))
df <- data.frame(Distribution = c("Prior","Data","Posterior"),
Mean = c(mu0,mean_t,post_mean),
SD = c(sigma0,se,post_sd))
df
post_mean

x <- seq(10, 145, length=10000)
priorx <- dnorm(x, mean=mu0, sd=sigma0)
datax <- dnorm(x, mean=mean_t, sd=se)
postx <- dnorm(x, mean=post_mean, sd=post_sd)
plot(x, priorx, type='l',lwd=3,xlim = c(95,145),ylim=c(0,0.3),
col = 'blue', main = '', xlab = 'theta', ylab = '')
lines(x, datax,col='black',lwd=3)
lines(x, postx,col='red',lwd=3)
legend("topleft", c("Prior","Data","Posterior"), lty = 1, lwd= 3,
col = c('blue','black','red'))


```
The posterior has shifted to the left towards the data. Our prior belief is a normal distribution $X\sim N(\theta,\sigma^2)$ with mean equal to 130 and $\sigma$ = 30. The mode is now approximately 116 minutes. We can see the distribution is more precise than both the data and prior, taking advatange of combining information from both.

Lets investigate if the data is normally distributed?
```{r}
qqnorm(times,main="QQ plot of normal data",pch=19)
qqline(times)

shapiro.test(times)
```
Ho: The data is normaly distributed.
Ha: The data is not normally distributed.

From the Shapiro-Wilk normality test we can see the p-value is 0.5226. This is greater than 0.05 so we fail to reject the null hypothesis.

There is evidence to suggest that the times I gathered are normally distributed.

Point and interval estimate for $\theta$ using our posterior
```{r}
#Point estimate is the posterior mean
116.2244

#Interval estimate
qnorm(0.025, mean = post_mean, sd = post_sd)
qnorm(0.975, mean = post_mean, sd = post_sd)
plot(x, postx, type='l', xlim = c(105,125), ylim = c(0,0.3), lwd=3, col = 'red', main = 'Posterior',xlab = 'theta', ylab = '')
abline(v= qnorm(0.025, mean = post_mean, sd = post_sd), lty = 'dashed', lwd = 2)
abline(v= qnorm(0.975, mean = post_mean, sd = post_sd), lty = 'dashed', lwd = 2)

```
From the interval estimation we can conclude that the probability that $\theta$ lies between 113.2696 and 119.1791 is 0.95.

Lets investigate the claim that students' average daily screen time is 90 minutes. How can we test this claim?
```{r}
1 - pnorm(90, mean=post_mean,sd=post_sd)
```
There is a probability of 1 that the average daily screen time for a student is 30 minutes or longer. We reject the psychologists claim.

Simulate 10000 values from your posterior distribution for $\theta$.
```{r}
my_sims <- rnorm(10000, mean = post_mean, sd = post_sd)
```

```{r}
quantile(my_sims, probs = c(0.025, 0.975))
```
Like our other examples, the 95% probability interval obtained from simulating 10,000 observations is very close to the interval we obtained earlier. We observe that the upper and lower quartiles generated from the simulated data are approximately equal to the upper and lower quartiles we found earlier. We expect as the number of simulations increases we will obtain an interval closer in value to that of the one we obtained earlier.