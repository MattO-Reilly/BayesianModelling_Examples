---
title: "Bayesian_Project"
author: Matt O'Reilly and Kordian Pawelec
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

*Libraries*
```{r}
library(tidyverse)
library(ggExtra)
library(ggplot2)
source('TeachBayes.r')
library(rjags)
library(ggpubr)
```

###Aim
2020 marked the first-ever occurence of predicted grades for students in Ireland. The Irish Government had to provide an estimated mark across all subjects for each student in the country. There were many issues with their model.So, Using Bayesian Statistics and a dataset of student grades, we want to build a model that can predict an end of year grade from personal and academic characteristics.

Our objective is to create a model that can acuurately predict end of year grades based on student information. We will aim to use variables like Mock Examination Results, Gender, Study Time, Absences, Failures, and Parents Education to predict their end of year grade. 

###Subjective Impression

We found a dataset online \href{https://archive.ics.uci.edu/ml/datasets/Student+Performance}{here}. The dataset included grades and student information for 1044 students taken from a school in Portugal. The portuguese system measures grades from 0 to 20 and for convenience we have multiplied the grades by 5 to get a grade out of 100.  
```{r}
#Load data from Github
math_student_data_url <- "https://raw.githubusercontent.com/arunk13/MSDA-Assignments/master/IS607Fall2015/Assignment3/student-mat.csv";
math_student_data <- read.table(file = math_student_data_url, header = TRUE, sep = ";");
eng_student_data_url <- "https://raw.githubusercontent.com/arunk13/MSDA-Assignments/master/IS607Fall2015/Assignment3/student-por.csv";
eng_student_data <- read.table(file = eng_student_data_url, header = TRUE, sep = ";")
studentdata <- rbind(math_student_data, eng_student_data)


#Clean Data
studentdata[c("G1","G2","G3")] <- studentdata[c("G1","G2","G3")] * 5

```

#Estimate Mean Grade
```{r}
studentdata %>% summarise(N=n(), mean = mean(studentdata$G3), sd = sd(studentdata$G3))
```
There are N=1044 students in our dataset, The mean final grade is 56.70977 while the standard deviation is 19.32398. With normal data, most of the observations are spread within 3 standard deviations on each side of the mean.



#Defining prior
```{r}
m0 <- 60
se <- 19.32398/sqrt(1044)
s0 <- 1 #Sigma_0 (Using a larger value for sigma_0 to allow for extra variation in Final Grade)
```

#Likelihood
```{r}
xbar <- mean(studentdata$G3)
sigma <- 15
n = length(studentdata$G3)
se <- sigma/sqrt(n)

```

###Formal Analysis

#Plot the prior, data and posterior
```{r}
Prior <- c(m0, s0)
Data <- c(xbar, se)
Posterior <- round(normal_update(Prior, Data),3)
x <- seq(0, 100, length=1000)
priorx <- dnorm(x, mean=m0,   sd=s0)
datax  <- dnorm(x, mean=xbar, sd=se)
postx  <- dnorm(x, mean=Posterior[1], sd=Posterior[2])
plot(x, priorx, type='l',lwd=3,xlim = c(50,65),ylim=c(0,1),col = 'blue', main = '', xlab = 'theta', ylab = '')
lines(x, datax,col='black',lwd=3)
lines(x, postx,col='red',lwd=3)
legend("topright", c("Prior","Data","Posterior"), lty = 1, lwd= 3, col = c('blue','black','red'))
```
The posterior has shifted to the left towards the data. Our prior belief is a normal distribution $X\sim N(\theta,\sigma^2)$ with mean = 60 and $\sigma$ = 1. The mode is now approximately 57. We can see the distribution is more precise than both the data and prior, taking advatange of combining information from both.

#Measures of spread
```{r}
mysims <- rnorm(10000, mean = Posterior[1], sd = Posterior[2])
diff(quantile(mysims, probs = c(0.25,0.75)))
```


##Comparing Grades by Sex
```{r}
studentdata %>% group_by(sex) %>% summarise(mean = mean(G3), n = length(sex), sigma = sd(G3))

n_F <- sum(studentdata$sex=='F')
n_M <- sum(studentdata$sex=='M')
```
Summarising the mean grade by sex we can see that females have a mean grade (=57.24) slightly higher than males (=56.02). However, the difference is quite small.

```{r}
xbar1_F <- studentdata %>% filter(studentdata$sex == 'F') %>% 
  summarise(mean(G3)) %>% as.numeric()
xbar2_M <- studentdata %>% filter(studentdata$sex == 'M') %>% 
  summarise(mean(G3)) %>% as.numeric()
Prior <- c(m0, s0)
Grades_Female <- c(xbar1_F, se)
Grades_Male <- c(xbar2_M, se)
Posterior1_F <- normal_update(Prior, Grades_Female)

Posterior2_M <- normal_update(Prior, Grades_Male)

many_normal_plots(list(Prior,Posterior1_F,Posterior2_M)) + theme(legend.position = c(0.75,0.75))
```
From the plot above, The Blue curve is our prior. The red curve represents the average final grade of male students, which has a mode of 57.0651757. The green distribution represents the average final grade of female students, which has a mode of 57.9685636.

#Estimate Mean and SD using rjags
```{r}
# Take 10000 samples from the theta prior
prior_m <- rnorm(10000, 56.7, 15)
# Take 10000 samples from the sigma prior 
prior_s <- runif(10000, 0, 50)
samples <- data.frame(prior_m, prior_s)

grade_model <- "model{
  #Likelihood model for X
  for(i in 1:length(X)) {
      X[i] ~ dnorm(theta, sigma^(-2))
  }

  # Prior models for theta and sigma
  theta ~ dnorm(56.7, 15^(-2))
  sigma ~ dunif(0, 50)
}"

grade_jags <- jags.model(textConnection(grade_model), data = list(X = studentdata$G3),
    inits = list(.RNG.name = "base::Wichmann-Hill", .RNG.seed = 1989))

grade_sim <- update(grade_jags, n.iter = 10000)    
# SIMULATE the posterior  
n = 20000
grade_sim <- coda.samples(model = grade_jags, 
                         variable.names = c("theta","sigma"), 
                         n.iter= n)
head(grade_sim)
summary(grade_sim)


# PLOT the posterior    
plot(grade_sim, density = FALSE)

# PLOT the posterior    
plot(grade_sim, trace = FALSE)

# Store the chains in a data frame
grade_chains <- data.frame(sim = 1:n, grade_sim[[1]])
# Check out the head of rent_chains
head(grade_chains)

mean(grade_chains$sigma)
mean(grade_chains$theta)
range(grade_chains$theta)
```
It is desirable to have stability in the trace plot (no patterns), with good mixing (ie.chain traverses the parameter space without getting stuck or missing a section). From our trace plots for Sigma and Theta we can see they have no patterns and there is good mixing, this indicates that they are stable. The density plots are also normally distributed. From the summary function we see that standard error of the mean of the MCMC chain is 0.004. It is desirable to have a high ratio of meean to SE and that is what we have. The mean grade is appoximately between 54.8 and 58.5, Whereas the standard deviation density follows roughly the same uniform distribution as before

#Running multiple chains
```{r}
# COMPILE the model
grade_jags_multi <- jags.model(textConnection(grade_model), 
                              data = list(X = studentdata$G3), 
                              n.chains = 4)   
# UPDATE the model    
grade_sim_multi <- update(grade_jags_multi,
                         n.iter = 10000)
# SIMULATE the posterior    
grade_sim_multi <- coda.samples(model = grade_jags_multi, 
                               variable.names = c("theta", "sigma"), 
                               n.iter = 20000)
head(grade_sim_multi)

# Construct trace plots of the theta and sigma chains
plot(grade_sim_multi, density = FALSE)

# Construct density plots of the theta and sigma chains
plot(grade_sim_multi, trace = FALSE)

grade_chains_multi <- data.frame(sim = rep(1:20000,4),
                                chain = c(rep(1,20000),
                                          rep(2,20000),
                                          rep(3,20000),
                                          rep(4,20000)),
                                rbind(grade_sim_multi[[1]],
                                      grade_sim_multi[[2]],
                                      grade_sim_multi[[3]],
                                      grade_sim_multi[[4]]))

grade_chains_multi %>% filter(sim<1000) %>%
ggplot(aes(x=sim,y=theta,color=as.factor(chain))) + geom_line() + 
  geom_smooth(aes(color=as.factor(chain)),se=FALSE)
```
**Gelman-Rubin diagnostic**
```{r}
gelman.diag(grade_sim_multi)
gelman.plot(grade_sim_multi)
```
Here both m and s appear to converge to 1 at around the same rate. This is what we want in this case as it tells us that the chain have converged to the stationary distribution.

```{r}
autocorr.plot(grade_sim)
```
There is no correlation between the iterates of \(theta\), while there is minimal correlation for \(sigma\). 

```{r}
ci95 <- quantile(grade_chains_multi$theta , probs = c(0.025 , 0.975))

ggplot(grade_chains_multi , aes(x=theta)) + geom_density() + geom_vline(xintercept = ci95 , col = 'red' , lty = 'dashed')
```
Here there is a 95% chance that the mean grade is between 55.54 and 57.87.


##Bayesian Regression (Time spent studying and grades)
```{r}
studytime_model <- "model{
    # Likelihood model for Y[i]
    for(i in 1:length(Y)) {
      m[i] <- a + b * X[i]
      Y[i] ~ dnorm(m[i], s^(-2))
    }

    # Define the a, b, s priors
    a ~ dnorm(0, 19^(-2))
    b ~ dnorm(0, 19^(-2))
    s ~ dunif(0, 30)}"

studytime_jags <- jags.model(textConnection(studytime_model), 
                        data = list(Y = studentdata$G3, 
                                    X = studentdata$studytime), 
                        n.chains = 4)

# BURN IN the model
studytime_sim <- update(studytime_jags, n.iter = 10000)
# SIMULATE the posterior    
studytime_sim <- coda.samples(model=studytime_jags,
                         variable.names=c("a","b","s"),
                         n.iter=20000,
                         thin = 10)
```


```{r}
plot(studytime_sim[[1]][,1], main = 'a')
plot(studytime_sim[[1]][,2], main = 'b')
plot(studytime_sim[[1]][,3], main = 's')
```


```{r}
summary(studytime_sim)
```

```{r}
gelman.diag(studytime_sim)
gelman.plot(studytime_sim[,1:3])
autocorr.plot(studytime_sim[[1]][,1:3])
```
Since the median converges to 1 quite quickly, this suggests the chains have converged to the stationary distribution

```{r}
studytime_chains <- data.frame(studytime_sim[[1]])
quantile(studytime_chains$b, probs = c(0.025,0.975))

# Summarise the posterior Markov chains
summary(studytime_sim)[1]
# Summarise the posterior Markov chains
summary(studytime_sim)[2]

ggplot(studytime_chains, aes(x = b)) + geom_density() + 
  geom_vline(xintercept = quantile(studytime_chains$b, probs = c(0.025,0.975)), color = 'red')
```

There is a positive association between time studied and grade achieved
For every 1 unit of increase in Study time, End of semester grade (G3) increases by 3.94
The 95% credible interval for End of semester grade (G3) is from 2.47 to 5.24 change per unit increase in study time.


##grades per day missed
```{r}
absence_model <- "model{
    # Likelihood model for Y[i]
    for(i in 1:length(Y)) {
      m[i] <- a + b * X[i]
      Y[i] ~ dnorm(m[i], s^(-2))
    }
    # Define the a, b, s priors
    a ~ dnorm(0, 19^(-2))
    b ~ dnorm(0, 19^(-2))
    s ~ dunif(0, 30)}"
absence_jags <- jags.model(textConnection(absence_model), 
                        data = list(Y = studentdata$G3, 
                                    X = studentdata$absences), 
                        n.chains = 4)
# BURN IN the model
absence_sim <- update(absence_jags, n.iter = 10000)
# SIMULATE the posterior    
absence_sim <- coda.samples(model=absence_jags,
                         variable.names=c("a","b","s"),
                         n.iter=20000,
                         thin = 10)
```


```{r}
plot(absence_sim[[1]][,1], main = 'a')
plot(absence_sim[[1]][,2], main = 'b')
plot(absence_sim[[1]][,3], main = 's')

summary(absence_sim)
```
It is desirable to have stability in the trace plot (no patterns), with good mixing (ie.chain traverses the parameter space without getting stuck or missing a section). Here the trace plots have good mixing for both a, b and s, however the stability of both of them isn’t what we are looking for. The density plots are what we expected based on the prior we used. It is desirable to have a high ratio of meean to SE and that is what we have.

```{r}
gelman.diag(absence_sim)
gelman.plot(absence_sim[,1:3])
autocorr.plot(absence_sim[[1]][,1:3])
```
Here a and s appear to converge to 1 at around the same rate. This is what we want in this case as it tells us that the chain have converged to the stationary distribution. However s appears to converge at a much slower rate.

There is no correlation between the iterates of \(a\), \(b\) or \(s\)


```{r}
absence_chains <- data.frame(absence_sim[[1]])
quantile(absence_chains$b, probs = c(0.025,0.975))
# Summarise the posterior Markov chains
summary(absence_sim)[1]
# Summarise the posterior Markov chains
summary(absence_sim)[2]
ggplot(absence_chains, aes(x = b)) + geom_density() + 
  geom_vline(xintercept = quantile(absence_chains$b, probs = c(0.025,0.975)), color = 'red')
```
There is an almost completely negative association between absences and grade achieved
For every 1 unit of increase in absences, End of semester grade (G3) decreases by 0.14.
The 95% credible interval for End of semester grade (G3) is from -0.33 to 0.06 change per unit increase in absences.



###Bayesian Multiple Regression
```{r}
# DEFINE the model    
grade_model_mult <- "model{
    # Define model for data Y[i]
    for(i in 1:length(Y)) {
      Y[i] ~ dnorm(m[i], s^(-2))
      m[i] <- a + c*X2[i] + d*X3[i]
    }

    # Define the a, b, c, d and s priors
    a ~ dnorm(0, 50^(-2))
    c ~ dnorm(3.94, 2.77^(-2)) #studytime
    d ~ dnorm(-0.13, 0.26^(-2)) #absences
    s ~ dunif(0, 20)
}"  
```

```{r}
# mean centre the grades and studytime 
#studentdata$G3 = (studentdata$G3 - mean(studentdata$G3))
#studentdata$studytime = (studentdata$studytime - mean(studentdata$studytime)) 
# COMPILE the model
grades_jags_mult <- jags.model(textConnection(grade_model_mult), 
                        data = list(Y = studentdata$G3,
                                    X2 = studentdata$studytime, X3 = studentdata$absences), 
                        inits = list(.RNG.name="base::Wichmann-Hill",.RNG.seed = 1989))

# BURN IN the model
grades_sim_mult <- update(grades_jags_mult,n.iter=10000)
# SIMULATE the posterior    
grades_sim_mult <- coda.samples(model=grades_jags_mult,
                                variable.names=c("a","c","d","s"),
                                n.iter=20000)

plot(grades_sim_mult[[1]][,1], density = TRUE, main = "a")
plot(grades_sim_mult[[1]][,2], density = TRUE, main = "c")
plot(grades_sim_mult[[1]][,3], density = TRUE, main = "d")
plot(grades_sim_mult[[1]][,4], density = TRUE, main = "s")

```
It is desirable to have stability in the trace plot (no patterns), with good mixing (ie.chain traverses the parameter space without getting stuck or missing a section). Here the trace plots have good mixing for a, c, d and s. 
The mean is approx.between 8 and 32 minutes. Whereas the standard deviation density follows roughly the same uniform distribution as before.From the summary function we see that standard error of the mean of the MCMC chain is 0.06. It is desirable to have a high ratio of meean to SE and that is what we have.




```{r}
summary(grades_sim_mult)[1]
summary(grades_sim_mult)[2]
```



